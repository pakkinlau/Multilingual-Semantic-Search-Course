{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the procedure in other notebook to import dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import random\n",
    "from pprint import pprint\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Define the paths to the dataset files\n",
    "english_dataset_path = r'./dataset/News-Commentary/News-Commentary.en-zh.en'\n",
    "chinese_dataset_path = r'./dataset/News-Commentary/News-Commentary.en-zh.zh'\n",
    "\n",
    "# Function to get random sentence pairs\n",
    "def get_random_sentence_pairs(english_path, chinese_path, num_pairs=1):\n",
    "    with open(english_path, 'r', encoding='utf-8') as eng_file, \\\n",
    "         open(chinese_path, 'r', encoding='utf-8') as zh_file:\n",
    "        \n",
    "        # Read all lines from both files\n",
    "        english_lines = eng_file.readlines()\n",
    "        chinese_lines = zh_file.readlines()\n",
    "        \n",
    "        # Ensure both files have the same number of lines\n",
    "        if len(english_lines) != len(chinese_lines):\n",
    "            print(\"Error: The files don't have the same number of lines.\")\n",
    "            return None\n",
    "\n",
    "        # Generate random indices\n",
    "        random_indices = random.sample(range(len(english_lines)), num_pairs)\n",
    "        \n",
    "        # Get the random sentence pairs\n",
    "        sentence_pairs = [(english_lines[index].strip(), chinese_lines[index].strip()) for index in random_indices]\n",
    "        \n",
    "        return sentence_pairs\n",
    "\n",
    "# Function to compute and print the cosine similarity scores\n",
    "def print_similarity_scores(sentence_pairs):\n",
    "    \n",
    "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "    # Separate the sentence pairs\n",
    "    sentences1, sentences2 = zip(*sentence_pairs)\n",
    "\n",
    "    # Compute embedding for both lists\n",
    "    embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine-similarities\n",
    "    cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "    # Output the pairs with their score\n",
    "    for i in range(len(sentences1)):\n",
    "        print(f\"{sentences1[i]} \\n {sentences2[i]} \\n Score: {cosine_scores[i][i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "During the Cold War, America's approach to the Middle East was to foster stability in order to prevent the spread of Soviet influence, ensure the supply of oil, and provide security for Israel. The American strategy was management through autocratic leaders, and a \"don't rock the boat\" approach. \n",
      " 冷战时期，美国的中东策略是促进地区稳定，防止苏联影响的进一步蔓延，及确保石油供应和以色列的安全。 美国的战略是靠独裁领袖实现统治，始终抱着一种\"维持现状\"的态度。 \n",
      " Score: 0.1004\n",
      "Countries considering agreements like the Trans-Pacific Partnership or bilateral “partnership” agreements with the US and Europe need to be aware that this is one of the hidden objectives. What are being sold as “free-trade agreements” include IP provisions that could stifle access to affordable medicines, with a potentially significant impact on economic growth and development. \n",
      " 从全球看，越来越多的人认识到需要更加平衡的知识产权机制。 但制药行业为了巩固自己的利益，一直在推行更强势、更不平衡的知识产权机制。 考虑和美国和欧洲构建跨太平洋合作伙伴关系协定或双边“合作伙伴”协定的国家必须清楚，这是隐含目标之一。 它们兜售的是“自由贸易协定 ” ， 其中的知识产权保护条款可能阻挠人民获得负担得起的药品，对经济增长和发展起着潜在重大影响。 \n",
      " Score: 0.1960\n",
      "A large-scale program to reboot America’s crumbling infrastructure would go a long way toward addressing this gap between assets and liabilities, providing pension funds with investments with long time horizons (and thus guaranteeing the incomes of tomorrow’s retirees) while leveraging private capital for the public good. In fact, US pension funds are already investing in infrastructure, but they are doing so in Canada, Australia, the United Kingdom, and the Netherlands. \n",
      " 重振美国拙劣的设施的大计划极有利于解决这一资产和负债之间的缺口，为退休基金提供长期投资机会（从而确保未来退休者的收入 ） ， 同时撬动私人资本投资公共品。 事实上，美国退休基金已经开始投资基础设施，但投资的是加拿大、澳大利亚、英国和荷兰的基础设施。 \n",
      " Score: 0.1397\n",
      "For example, with the right support, the skies above developing countries could be filled with drones delivering medical supplies to remote hospitals. This is already happening in rural Rwanda, where a unique partnership between the health ministry and Zipline, a Silicon Valley-based tech startup, is giving doctors in hard-to-reach clinics the ability to order blood by text message, and then have it arrive by parachute in a matter of minutes. \n",
      " 比如，在正确的支持下，可以用无人机向发展中国家的偏远医院运送药品补给。 卢旺达农村已经在这么做，该国卫生部和硅谷科技初创企业Zipline进行了独到的合作，帮助难以进入地区的诊所实现短信预定血浆，并在几分钟内通过空投投送。 该计划自2016年10月开始实施以来，投送时间已经缩短了五倍，拯救了数百人的生命。 \n",
      " Score: 0.1836\n",
      "WASHINGTON, DC – Recent violence in Kazakhstan and Tajikistan, following civil strife in Kyrgyzstan in 2010, has intensified international concern about Central Asia’s security as the region becomes increasingly important for delivering NATO supplies to the International Security Assistance Force (ISAF) in Afghanistan. \n",
      " 华盛顿—继2010年哈萨克斯坦内乱后，最近的哈萨克斯坦和塔吉克斯坦暴力事件加剧了国际社会对中亚安全的忧虑。 作为北约向阿富汗国际维和部队（ISAF）补给线，该地区的重要性正变得越来越显著。 \n",
      " Score: 0.3068\n"
     ]
    }
   ],
   "source": [
    "# Load the SentenceTransformer model\n",
    "\n",
    "# Example usage:\n",
    "# Generate 5 random sentence pairs\n",
    "num_of_gen = 5\n",
    "sentence_pair = get_random_sentence_pairs(english_dataset_path, chinese_dataset_path, num_of_gen)\n",
    "\n",
    "# Compute and print the similarity scores for the sentence pairs\n",
    "if sentence_pair:\n",
    "    print_similarity_scores(sentence_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The similarity score is surprisingly low.\n",
    "\n",
    "Reasons:\n",
    "- 1. Cross-lingual Embeddings Challenge: However, cross-lingual semantic similarity can be particularly challenging, especially when dealing with languages that are structurally different, like English and Chinese. These languages not only differ in grammar and syntax but also in cultural context and expression.\n",
    "- 2. Literal vs Contextual Meaning: The model may be capturing the literal translation of words rather than the contextual meaning of the whole sentence. This can lead to lower scores if the sentence structure or idiomatic expressions vary significantly between the two languages.\n",
    "- 3. Quality of the Model: While SentenceTransformer models are generally quite good, their performance on specific language pairs can vary. There might be better-suited models for English-Chinese similarity specifically, such as those trained on cross-lingual datasets.\n",
    "- 4. Model's Training Data: If the model hasn't been trained on a diverse enough dataset that includes similar sentence pairs to those you're comparing, its ability to accurately measure similarity across languages may be limited.\n",
    "- 5. Embedding Space Alignment: For cross-lingual similarity, the embedding spaces of both languages must be well-aligned. If the alignment is not accurate, even semantically similar sentences might end up far apart in the embedding space, resulting in low similarity scores.\n",
    "- 6. Complex Sentences: The examples given include relatively complex sentences with multiple clauses and potentially nuanced meanings. The model might struggle more with these than with simpler, more straightforward sentences.\n",
    "- 7. Possible Errors: Ensure there are no errors in data preprocessing, such as incorrect sentence pairings or issues with text encoding that could affect the embeddings generated by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
